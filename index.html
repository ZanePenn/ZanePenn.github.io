
<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Zeng PENG's Homepage</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./assets_files/zengpeng.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets_files/icon.jpeg">
</head>

<div class="visible-phone" id="blackBar">
    <a href="#top">About</a>
    <!--<a href="#research">Research</a>-->
    <a href="#publications">Publications</a>
    <a href="#projects">Projects</a>
    <!--<a href="#teaching">Teaching</a>-->
    <a target="_blank"
       href="./assets_files/resume.pdf">Resume</a>
</div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <li><a href="#publications">Publications</a></li>
            <li><a href="#projects">Projects</a></li>
            <!--<li><a href="#teaching">Teaching</a></li>-->
            <li><a target="_blank"
                   href="./info/resume.pdf">Resume</a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets_files/head.jpg" width="180" alt="photo" class="logo-image">
            <br><br>
            zeng.peng at outlook dot com <br>
            <!--
	    <img src="./assets_files/qq.png" class="icon-adjust"> 1036303100
            <img src="./assets_files/wechat.png" class="icon-adjust"> zjf23336666<br> 
	    -->
        </div>

        <!-- Otherwise, we simply use a flat list of links -->

    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                Zeng PENG (彭曾)
            </h3>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <a class="visible-phone pull-left" href="http://daggerfs.com/index.html#">
                <img class="media-object" src="assets_files/head.jpg" width="96px" style="margin: 0px 10px">
            </a>

            <p>
                My name is Zeng PENG, I am an undergraduate student at Northwest A&F University (985&211), China,
                with a major in software engineering,
            </p>
            <p>
                My main research interests lie in computer vision, deep learning, especially in segmentation,
                and published one international conference poster paper mainly about using deep learning to solve segmentation
                problem in agriculture and medical area last year, and now I am a full-time research intern in DEEP-HRI
                (Hikvision Research Institute) doing deep learning in computer vision.
                <p><strong>Currently applying for Ph.D. Also open to one-year research position. If you're interested, don’t hesitate to contact me.</strong> Here's my <a target="_blank"
                            href="./info/resume.pdf">Resume</a>.
            </p>


            <!--
             *** Research ***
            -->
            <!--<h3>-->
            <!--<a name="research"></a> Research-->
            <!--</h3>-->
            <!--<p>-->
            <!--My current research topics include:-->
            <!--</p><ul>-->
            <!--<li> Learning better structures for image feature extraction.-->
            <!--</li><li> Explaining human generalization behavior with visually grounded cogscience models.-->
            <!--</li><li> Making large-scale vision feasible and affordable.-->
            <!--</li></ul>-->
            <!--<p></p>-->
            <!--<p> (Most recent publications to be added) </p>-->


            <!--
             *** Publications ***
            -->
            <h3>
                <a name="publications"></a> Publications
            </h3>

        <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/jh_graphabstract.png" width="96px" height="130px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Developing a Long Short-Term Memory (LSTM) based Model for Predicting Water Table Depth in Agricultural Areas
                     </strong><br>
                        <strong>Jianfeng Zhang</strong>, Yan Zhu, Xiaoping Zhang, Ming Ye, Jinzhong Yang, <i>Journal of Hydrology</i>
			<a target="_blank"
                           href="./publications/JH2018.pdf">[paper]</a>
                        <a target="_blank"
                           href="https://github.com/jfzhang95/LSTM-water-table-depth-prediction">[code]</a> 
                    </p>
                    <p class="abstract-text">
                        Predicting water table depth over the long-term in agricultural
						areas presents great challenges because these areas have complex
						and heterogeneous hydrogeological characteristics, boundary conditions,
						and human activities; also, nonlinear interactions occur
						among these factors. Therefore, we developed a new time series model 
						based on Long Short-Term Memory (LSTM) in this study as an alternative to computationally
						expensive physical models.In this study, the proposed model was 
						applied and evaluated in five sub-areas of Hetao Irrigation District in 
						arid northwestern China using data of 14 years (2000-2013). 14 years of data are 
						separated into two sets: training set (2000-2011) and validation set (2012-2013) in the experiment. 
						The proposed model achieves higher R2 scores (0.789-0.952) in water table depth prediction,
						when compared with the results of traditional feed-forward neural network (FFNN), 
						which only reaches relatively low R2 scores (0.004-0.495).
						Furthermore, we discussed the validity of the dropout method 
						and the proposed model’s architecture. Through experimentation, the results
						show that the proposed model’s architecture is reasonable and can contribute
						to a strong learning ability on time series data.
                    </p>
                </div>
            </div>        

            

            <h3>
                <a name="projects"></a> Projects
            </h3>
            Link to my <a target="_blank" href="https://github.com/jfzhang95">[github public projects]</a>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/tvseg_result.png"
                         width="96px" height="130px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Total Variation Image segmentation Model based on Primal-dual Method
                        </strong>
                        <a target="_blank"
                           href="https://github.com/jfzhang95/TV_Segmentation/blob/master/notes.pdf">[pdf]</a>
                        <a target="_blank"
                           href="https://github.com/jfzhang95/TV_Segmentation">[code]</a>
                    </p>
                    <p class="abstract-text">
						We implement total variation image segmentation model and 
						applied Primal-dual method to optimize it. Besides, we also 
						combine the model with K-means to improve the final results.
                    </p>
                </div>
            </div>
			
			
	<div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/rgbd_cut.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Interactive Segmentation on RGBD Image
                        </strong>
						<a target="_blank"
                           href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Feng_Interactive_Segmentation_on_CVPR_2016_paper.pdf">[arXiv]</a>
                        <a target="_blank" href="https://github.com/ZVsion/rgbd_image_segmentation">[code]</a>
                    <p class="abstract-text">
						We replicate “Interactive Segmentation on RGBD Images via Cue Selection”,
						this paper proposes a novel interactive segmentation algorithm which can incorporate 
						multiple feature cues like color, depth and normals in a graph cut framework.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/deeplab.png"
                         width="96px" height="96px">
                </a>

                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            PyTorch-Deeplab V3+
                        </strong>
                        <a target="_blank"
                           href="https://arxiv.org/pdf/1802.02611.pdf">[arXiv]</a>
                        <a target="_blank" href="https://github.com/jfzhang95/pytorch-deeplab-xception">[code]</a>
                    <p class="abstract-text">
						We reimplement Deeplab v3+ with Xception as backbone in PyTorch from scratch,
						and evaluate it on Pascal Voc 2012 dataset.
                    </p>
                </div>
            </div>
			

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/dgc_demo.gif"
                         width="96px" height="96px">
                </a>

                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Deep Grabcut (DeepGC)
                        </strong>
                        <a target="_blank"
                           href="https://arxiv.org/abs/1707.00243">[arXiv]</a>
                        <a target="_blank" href="https://github.com/jfzhang95/DeepGrabCut-PyTorch">[code]</a>
                    <p class="abstract-text">
						We replicate "Deep Grabcut for Object Selection", this paper proposes 
						a segmentation approach that uses a rectangle as a soft constraint by 
						transforming it into an Euclidean distance map. A convolutional 
						encoder-decoder network is trained end-to-end by concatenating images
						with these distance maps as inputs and predicting the object masks as outputs.
						We implement this paper using PyTorch and trained this model using 
						Pascal Voc 2012 and SBD datasets. 
                    </p>
                </div>
            </div>
			
			
	<div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/pw_demo.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Chinese_Poem_Writer
                        </strong>
                        <a target="_blank" href="https://github.com/jfzhang95/Chinese_Poem_Writer">[code]</a>
                    <p class="abstract-text">
						We build a Chinese poem writer based on Temporal Convolutional Networks (TCN). 
						Recently a research group indicates that a simple TCN architecture outperforms RNNs
						across a diverse range of tasks and datasets, while demonstrating longer effective memory. 
						Therefore, we build this Chinese poem writer using TCN.
                    </p>
                </div>
            </div>
			
			
			<div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/VideoSeg.gif"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Video Object Segmentation Framework
                        </strong>
                        <a target="_blank" href="http://jeff95.me">[code will be available soon]</a>
                    <p class="abstract-text">
						We build a Video Object Segmentation Framework. It can perform key frame extraction 
						based on VGG16 and interactive object segmentation for online fine-tune. 
						Only 200~3000 iters of online fine-tune can reach very good video object segmentation results.
                    </p>
                </div>
            </div>
			
			
			<div class="media">
                <a class="pull-left">

                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            End to end network image text detection and recognition.
                        </strong>
                        <a target="_blank" href="http://jeff95.me">[code will be available soon]</a>
                    <p class="abstract-text">
						We build a faster-rcnn like model for end to end network image text detection and recognition. 
						Our method achieve 0.634 accuracy and rank <b>13/1488</b> on <a target="_blank" href="https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.11165320.5678.1.2e31572eYD2QEf&raceId=231652">ICPR MTWI 2018 Challenge on Tianchi</a>.
                    </p>
                </div>
            </div>


            <div class="media">
                <a class="pull-left">

                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Clothing fashion style recognition.
                        </strong>
                        <a target="_blank" href="http://jeff95.me">[code will be available soon]</a>
                    <p class="abstract-text">
						We build our fashion style recognition based on se-resnet and vgg net. We
                        also apply image segmentation and model ensemble method to improve our result.
						Finally, our method achieve 0.6103 F2 score and rank <b>9/213</b> on <a target="_blank" href="https://fashion-challenge.github.io/#index">JD AI Fashion-Challenge</a>.
                    </p>
                </div>
            </div>
			
			

			

            <!-- Footer
            ================================================== -->
            <hr>
            <footer class="footer">
                <div class='hidden-phone'>
                <h3 class="text-center"><a name="wall"></a><strong>works</strong></h3>
                <section id="photos">
                    <img src="./assets_files/tvseg_result.png"/>
                    <img src="./assets_files/rgbd_cut.png"/>
                    <img src="./assets_files/pw_demo.png"/>
					<img src="./assets_files/watertable.png"/>
                    <img src="./assets_files/dgc_demo.gif"/>
					<img src="./assets_files/jh_graphabstract.png"/>
					<img src="./assets_files/VideoSeg.gif"/>
                </section>
                
                <a target="_blank" href="https://github.com/yihui-he/panorama"><img
                        src="https://github.com/yihui-he/panorama/blob/master/results/yellowstone5.jpg?raw=true"></a>
                <hr>
                </div>
                <div class="row">
                    <div class="span12">
                        <p>
                              <a target="_blank" href="#/">© Zeng PENG  2018</a>
                        </p>
                    </div>
                </div>
            </footer>
        </div>
    </div>
</div>
</body>
</html>


